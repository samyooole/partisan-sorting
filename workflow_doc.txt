- get voter file data
[chunking MUST be done at each stage of the process]
- get universe of addresses, then geocode it (arcpy script?) with a local copy of pointaddresses (arcgis/esri) 
- join on addresses to get latlon
- universe losses of around 10% - 15%


- then assign isolation measure ?? think long and hard about whether this is ACTUALLY necessary lmao. purely with cpu/numpy usage takes around probably 0.5h? for each 500MB dataset {around North Carolina size} //CONSIDER USING GPU , apparently brings down by a factor of 10 + cythonizing it

- consider imputing party affiliation with primary participation
--> when we impute with party affiliation, it's a bit more problematic because primaries only happen every 2 years, and it only effectively starts in 2013

next steps now:
1. download 